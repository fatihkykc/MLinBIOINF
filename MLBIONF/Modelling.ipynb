{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "maple_train_df = pd.read_csv('maple_train.csv')\n",
    "maple_test_df = pd.read_csv('maple_test.csv')\n",
    "maple_eval_df = pd.read_csv('maple_eval.csv')\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# maple_train_df[maple_train_df[\"Path\"] == \"nitrogen\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import os\n",
    "path = './PathwayFeatures'\n",
    "pathway_names = []\n",
    "pw_names = maple_eval_df[\"Path\"].unique()\n",
    "for i, attrlist in enumerate(os.listdir(path)):\n",
    "    attributes = pd.read_csv(path+'/'+ attrlist)\n",
    "    attributes = attributes[\"Attrib\"].tolist()\n",
    "    pathway_name = attrlist.split('-')[0]\n",
    "    pathway_names.append(pathway_name)\n",
    "\n",
    "    maple_train_df.loc[maple_train_df['Path'] == pathway_name.replace('_', ' '), 'Class'] = 'positive'\n",
    "    maple_test_df.loc[maple_test_df['Path'] == pathway_name.replace('_', ' '), 'Class'] = 'positive'\n",
    "    maple_eval_df.loc[maple_eval_df['Path'] == pathway_name.replace('_', ' '), 'Class'] = 'positive'\n",
    "\n",
    "    maple_train_df.loc[maple_train_df['Path'] != pathway_name.replace('_', ' '), 'Class'] = 'negative'\n",
    "    maple_test_df.loc[maple_test_df['Path'] != pathway_name.replace('_', ' '), 'Class'] = 'negative'\n",
    "    maple_eval_df.loc[maple_eval_df['Path'] != pathway_name.replace('_', ' '), 'Class'] = 'negative'\n",
    "\n",
    "    train_df_prep = maple_train_df[attributes]\n",
    "    test_df_prep = maple_test_df[attributes]\n",
    "    eval_df_prep = maple_eval_df[attributes]\n",
    "\n",
    "    train_df_prep.to_csv('Datasets/'+pathway_name+'_train.csv', index=False)\n",
    "    test_df_prep.to_csv('Datasets/'+pathway_name+'_test.csv', index=False)\n",
    "    eval_df_prep.to_csv('Datasets/'+pathway_name+'_eval.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "# by: @invoktheshell\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)):\n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, recall_score, precision_score\n",
    "\n",
    "def calc_metrics(y_true, y_pred, model_name, pw_name, dataset_name, fold_num):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    tp, fp, tn, fn = perf_measure(y_true, y_pred)\n",
    "    recall = precision_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    specifity = tn / (tn + fp)\n",
    "    # print(precision, specifity, tp,fp,tn,fn)\n",
    "    try:\n",
    "        fpr = fp / (fp + tn)\n",
    "    except:\n",
    "        fpr = 0\n",
    "    try:\n",
    "        tpr = tp / (tp + fn)\n",
    "    except:\n",
    "        tpr = 0\n",
    "    try:\n",
    "        fnr = fn / (fn + tp)\n",
    "    except:\n",
    "        fnr = 0\n",
    "    try:\n",
    "        fdr = fp / (fp + tp)\n",
    "    except:\n",
    "        fdr = 0\n",
    "    return model_name, pw_name, dataset_name, fold_num, acc, f1, mcc, tp, fp, tn, fn, recall, precision, specifity, fpr, tpr, fnr, fdr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathway:  amine_and_polyamine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-124-5d8426c90224>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     48\u001B[0m             \u001B[0mpreds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m             \u001B[0;31m# print(y_test[y_test[]])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m             \u001B[0mres\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcalc_metrics\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpreds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpathway_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'test_df'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfold_num\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0mres_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mres\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"model_name\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"pw_name\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"dataset_name\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fold_num\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"acc\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"f1\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"mcc\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"tp\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fp\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"tn\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fn\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"recall\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"precision\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"specifity\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fpr\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"tpr\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fnr\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fdr\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#.3 Metabolic pathway modeling and analysis\n",
    "# The 10-fold cross-validation and bagging were used on all training process,\n",
    "# and the metrics accuracy, percentage of correctly classified instances (CCI),\n",
    "# true positive (TP) rate, false positive (FP) rate, false negative (FN) rate, recall,\n",
    "# specificity, F-measure, false discovery rate (FDR), and Matthews coefficient correlation (MCC)\n",
    "# were used to evaluate the predictive performances.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# from collections import defaultdict\n",
    "# res_dict = defaultdict(list)\n",
    "res = []\n",
    "for pathway_name in pathway_names:\n",
    "    # if pathway_name=='amine_and_polyamine':\n",
    "    train_df = pd.read_csv('Datasets/'+ pathway_name+'_train.csv')\n",
    "    # test_df = pd.read_csv('Datasets/'+ pathway_name+'_test.csv')\n",
    "    # eval_df = pd.read_csv('Datasets/'+ pathway_name+'_eval.csv')\n",
    "    print('pathway: ', pathway_name)\n",
    "    # print(len(train_df[train_df[\"Class\"]=='positive']))\n",
    "    train_df[\"Class\"] = train_df[\"Class\"].apply(lambda x: 1 if x=='positive' else 0)\n",
    "    # test_df[\"Class\"] = test_df[\"Class\"].apply(lambda x: 1 if x=='positive' else 0)\n",
    "    # eval_df[\"Class\"] = eval_df[\"Class\"].apply(lambda x: 1 if x=='positive' else 0)\n",
    "    names = ['svc', 'nb', 'dt', 'mlp', 'knn', 'rf', 'sgd']\n",
    "    models = [BaggingClassifier(SVC()),\n",
    "              BaggingClassifier(GaussianNB()),\n",
    "              BaggingClassifier(DecisionTreeClassifier()),\n",
    "              BaggingClassifier(MLPClassifier()),\n",
    "              BaggingClassifier(KNeighborsClassifier()),\n",
    "              BaggingClassifier(RandomForestClassifier()),\n",
    "              BaggingClassifier(SGDClassifier()),]\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=1337)\n",
    "    X = train_df.drop('Class', axis=1)\n",
    "    y = train_df[\"Class\"]\n",
    "    for i in range(len(models)):\n",
    "        fold_num=0\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            fold_num+=1\n",
    "            X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "            y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "            models[i].fit(X_train, y_train)\n",
    "            preds = models[i].predict(X_test)\n",
    "            # print(y_test[y_test[]])\n",
    "            res.append(calc_metrics(y_test.tolist(), preds.tolist(), names[i], pathway_name, 'test_df', fold_num))\n",
    "\n",
    "res_df = pd.DataFrame(res, columns=[\"model_name\", \"pw_name\", \"dataset_name\", \"fold_num\", \"acc\", \"f1\", \"mcc\", \"tp\", \"fp\", \"tn\", \"fn\", \"recall\", \"precision\", \"specifity\", \"fpr\", \"tpr\", \"fnr\", \"fdr\"])\n",
    "res_df.to_csv('10fold_results.csv', index=False)\n",
    "del y_test, y_train, X_test, X_train, X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "                 acc        f1       mcc    tp     fp      tn    fn    recall  \\\nmodel_name                                                                      \ndt          0.986336  0.799392  0.799200  73.5   17.0  2633.5  20.5  0.842650   \nknn         0.994899  0.917251  0.919023  80.0    0.0  2650.5  14.0  1.000000   \nmlp         0.987064  0.826506  0.829699  80.5   22.0  2628.5  13.5  0.833333   \nnb          0.771891  0.216178  0.268064  79.0  611.0  2039.5  15.0  0.126741   \nrf          0.989980  0.827739  0.836314  66.5    0.0  2650.5  27.5  1.000000   \nsvc         0.995082  0.920074  0.921853  80.5    0.0  2650.5  13.5  1.000000   \n\n            precision  specifity       fpr       tpr       fnr       fdr  \nmodel_name                                                                \ndt           0.842650   0.993585  0.006415  0.781915  0.218085  0.157350  \nknn          1.000000   1.000000  0.000000  0.851064  0.148936  0.000000  \nmlp          0.833333   0.991698  0.008302  0.856383  0.143617  0.166667  \nnb           0.126741   0.769459  0.230541  0.840426  0.159574  0.873259  \nrf           1.000000   1.000000  0.000000  0.707447  0.292553  0.000000  \nsvc          1.000000   1.000000  0.000000  0.856383  0.143617  0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acc</th>\n      <th>f1</th>\n      <th>mcc</th>\n      <th>tp</th>\n      <th>fp</th>\n      <th>tn</th>\n      <th>fn</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>specifity</th>\n      <th>fpr</th>\n      <th>tpr</th>\n      <th>fnr</th>\n      <th>fdr</th>\n    </tr>\n    <tr>\n      <th>model_name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dt</th>\n      <td>0.986336</td>\n      <td>0.799392</td>\n      <td>0.799200</td>\n      <td>73.5</td>\n      <td>17.0</td>\n      <td>2633.5</td>\n      <td>20.5</td>\n      <td>0.842650</td>\n      <td>0.842650</td>\n      <td>0.993585</td>\n      <td>0.006415</td>\n      <td>0.781915</td>\n      <td>0.218085</td>\n      <td>0.157350</td>\n    </tr>\n    <tr>\n      <th>knn</th>\n      <td>0.994899</td>\n      <td>0.917251</td>\n      <td>0.919023</td>\n      <td>80.0</td>\n      <td>0.0</td>\n      <td>2650.5</td>\n      <td>14.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.851064</td>\n      <td>0.148936</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>mlp</th>\n      <td>0.987064</td>\n      <td>0.826506</td>\n      <td>0.829699</td>\n      <td>80.5</td>\n      <td>22.0</td>\n      <td>2628.5</td>\n      <td>13.5</td>\n      <td>0.833333</td>\n      <td>0.833333</td>\n      <td>0.991698</td>\n      <td>0.008302</td>\n      <td>0.856383</td>\n      <td>0.143617</td>\n      <td>0.166667</td>\n    </tr>\n    <tr>\n      <th>nb</th>\n      <td>0.771891</td>\n      <td>0.216178</td>\n      <td>0.268064</td>\n      <td>79.0</td>\n      <td>611.0</td>\n      <td>2039.5</td>\n      <td>15.0</td>\n      <td>0.126741</td>\n      <td>0.126741</td>\n      <td>0.769459</td>\n      <td>0.230541</td>\n      <td>0.840426</td>\n      <td>0.159574</td>\n      <td>0.873259</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>0.989980</td>\n      <td>0.827739</td>\n      <td>0.836314</td>\n      <td>66.5</td>\n      <td>0.0</td>\n      <td>2650.5</td>\n      <td>27.5</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.707447</td>\n      <td>0.292553</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>svc</th>\n      <td>0.995082</td>\n      <td>0.920074</td>\n      <td>0.921853</td>\n      <td>80.5</td>\n      <td>0.0</td>\n      <td>2650.5</td>\n      <td>13.5</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.856383</td>\n      <td>0.143617</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('10fold_results.csv').drop('fold_num', axis=1).groupby('model_name').mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KruskalResult(statistic=0.03386243386243255, pvalue=0.8539997400757506)\n",
      "KruskalResult(statistic=0.03379752777343008, pvalue=0.8541381599961391)\n",
      "KruskalResult(statistic=0.6104678454076083, pvalue=0.43461171245060526)\n",
      "KruskalResult(statistic=0.01904761904762454, pvalue=0.8902300549434817)\n",
      "KruskalResult(statistic=0.03386243386243255, pvalue=0.8539997400757506)\n",
      "KruskalResult(statistic=0.03386243386243255, pvalue=0.8539997400757506)\n",
      "KruskalResult(statistic=0.1714285714285639, pvalue=0.6788452994243248)\n",
      "KruskalResult(statistic=0.043598740082131965, pvalue=0.8346019409234209)\n",
      "KruskalResult(statistic=0.013456401259915306, pvalue=0.9076511710638686)\n",
      "KruskalResult(statistic=0.4752777343138738, pvalue=0.4905691312298255)\n",
      "KruskalResult(statistic=0.03386243386243255, pvalue=0.8539997400757506)\n",
      "KruskalResult(statistic=0.04289244528124076, pvalue=0.8359279247111269)\n",
      "KruskalResult(statistic=0.07619047619046967, pvalue=0.7825279247400765)\n",
      "KruskalResult(statistic=0.1714285714285639, pvalue=0.6788452994243248)\n",
      "KruskalResult(statistic=0.043598740082131965, pvalue=0.8346019409234209)\n"
     ]
    }
   ],
   "source": [
    "# The best classifiers for each metabolic pathway were ranked using the Kruskal-Wallis test.\n",
    "# Bu test algoritmaları nasıl sıralıyor anlamadım, benim anladığım fark varmı diye bakıyor dağılımlarda\n",
    "\n",
    "from scipy.stats import kruskal\n",
    "res_rows = res_df.drop('fold_num', axis=1).groupby('model_name').mean()\n",
    "for i in range(len(res_rows.index)):\n",
    "    for j in range(i+1, len(res_rows.index)):\n",
    "        kr = kruskal(res_rows.loc[str(res_rows.index[i])], res_rows.loc[str(res_rows.index[j])])\n",
    "        print(kr)\n",
    "        if kr.pvalue < 0.05:\n",
    "            print(\"statistically significant p value is found: \", str(res_rows.index[i], str(res_rows.index[j])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "0.9952639505324175\n",
      "{'dt__base_estimator__max_depth': 5, 'dt__base_estimator__min_samples_leaf': 6, 'svc__base_estimator__C': 1, 'svc__base_estimator__gamma': 0.1, 'svc__base_estimator__kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  9.0min finished\n"
     ]
    }
   ],
   "source": [
    "# her bir pathway için en iyi 3 classifier'ı seç (fp ve f measuer + kruskal-wallis test)\n",
    "# Seçilen classifierları votingclassifier ile birleştirip parametre optimizasyonu yap\n",
    "# burayı otomatikleştirmedim hangi pathwayler için hangi algoritmaların seçileceği belli olmadığı için\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# örnek votingclassifier modeli amine_and_polyamine pathwayi için\n",
    "amine_and_polyamine_model = VotingClassifier(estimators=[\n",
    "                        ('svc', BaggingClassifier(SVC())),\n",
    "                        ('nb', BaggingClassifier(GaussianNB())),\n",
    "                        ('dt', BaggingClassifier(DecisionTreeClassifier()))], voting='soft')\n",
    "amino_acid_model = []\n",
    "aromatic_compound_model = []\n",
    "carbohydrate_model = []\n",
    "carotenoid_model = []\n",
    "energy_model = []\n",
    "lipid_model = []\n",
    "nitrogen_model = []\n",
    "nucleotide_sugar_model = []\n",
    "phospholipid_model = []\n",
    "protein_modification_model = []\n",
    "secondary_metabolite_model = []\n",
    "models = [amine_and_polyamine_model]\n",
    "parameters = []\n",
    "# örnek parametre dictionary'si\n",
    "parameters_amine_and_polyamine = {\n",
    "                    'svc__base_estimator__C': [0.1, 1],\n",
    "                    'svc__base_estimator__gamma': [1, 0.1],\n",
    "                    'svc__base_estimator__kernel': ['rbf'],\n",
    "                    'dt__base_estimator__max_depth': list(range(3,6,1)),\n",
    "                    'dt__base_estimator__min_samples_leaf': list(range(4,10,2))\n",
    "                }\n",
    "\n",
    "\n",
    "parameters_rf = {\n",
    "                'base_estimator__bootstrap': [True],\n",
    "                'base_estimator__max_depth': [80, 90, 100],\n",
    "                'base_estimator__max_features': [2, 3],\n",
    "                'base_estimator__min_samples_leaf': [3, 4],\n",
    "                'base_estimator__min_samples_split': [8, 10],\n",
    "                'base_estimator__n_estimators': [100, 200]\n",
    "                }\n",
    "parameters_SVC={'base_estimator__C': [0.1, 1, 10, 100, 1000],\n",
    "              'base_estimator__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'base_estimator__kernel': ['rbf']\n",
    "                   }\n",
    "parameters_MLP = {\n",
    "    'base_estimator__hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'base_estimator__activation': ['tanh', 'relu'],\n",
    "    'base_estimator__solver': ['sgd', 'adam'],\n",
    "    'base_estimator__alpha': [0.0001, 0.05],\n",
    "    'base_estimator__learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "parameters_DT = {\n",
    "    'base_estimator__max_depth': list(range(1,10,1)),\n",
    "    'base_estimator__min_samples_leaf': list(range(1,10,2))\n",
    "}\n",
    "parameters_KNN = {\n",
    "    'base_estimator__n_neighbors': list(range(1, 31))\n",
    "}\n",
    "parameters_SGD = {\n",
    "    'base_estimator__C': [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "    'base_estimator__penalty': ['l2'],\n",
    "    'base_estimator__n_jobs': [-1]\n",
    "}\n",
    "parameters.append(parameters_amine_and_polyamine)\n",
    "#her bir pathway için seçilen modeller o pathwayin train setinde parametre optimizasyonu yapılacak\n",
    "for pathway_name in pathway_names:\n",
    "    if pathway_name == 'amine_and_polyamine':\n",
    "        df = pd.read_csv('Datasets/' + pathway_name+'_train.csv')\n",
    "        for i, model in enumerate(models):\n",
    "            clf = GridSearchCV(model, parameters, n_jobs=-1, verbose=3, scoring='f1_macro')\n",
    "            clf.fit(df.drop('Class', axis=1), df[\"Class\"])\n",
    "            print(clf.best_score_)\n",
    "            print(clf.best_params_)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=VotingClassifier(estimators=[('svc',\n                                                     BaggingClassifier(base_estimator=SVC())),\n                                                    ('nb',\n                                                     BaggingClassifier(base_estimator=GaussianNB())),\n                                                    ('dt',\n                                                     BaggingClassifier(base_estimator=DecisionTreeClassifier()))],\n                                        voting='soft'),\n             n_jobs=-1,\n             param_grid=[{'dt__base_estimator__max_depth': [3, 4, 5],\n                          'dt__base_estimator__min_samples_leaf': [4, 6, 8],\n                          'svc__base_estimator__C': [0.1, 1],\n                          'svc__base_estimator__gamma': [1, 0.1],\n                          'svc__base_estimator__kernel': ['rbf']}],\n             verbose=3)"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-41771fba",
   "language": "python",
   "display_name": "PyCharm (MLBIOINFINAL)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}