{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "maple_train_df = pd.read_csv('maple_train.csv')\n",
    "maple_test_df = pd.read_csv('maple_test.csv')\n",
    "maple_eval_df = pd.read_csv('maple_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# maple_train_df[maple_train_df[\"Path\"] == \"nitrogen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = './PathwayFeatures'\n",
    "pathway_names = []\n",
    "pw_names = maple_eval_df[\"Path\"].unique()\n",
    "for i, attrlist in enumerate(os.listdir(path)):\n",
    "    attributes = pd.read_csv(path+'/'+ attrlist)\n",
    "    attributes = attributes[\"Attrib\"].tolist()\n",
    "    pathway_name = attrlist.split('-')[0]\n",
    "    pathway_names.append(pathway_name)\n",
    "\n",
    "    maple_train_df.loc[maple_train_df['Path'] == pathway_name.replace('_', ' '), 'Class'] = 'positive'\n",
    "    maple_test_df.loc[maple_test_df['Path'] == pathway_name.replace('_', ' '), 'Class'] = 'positive'\n",
    "    maple_eval_df.loc[maple_eval_df['Path'] == pathway_name.replace('_', ' '), 'Class'] = 'positive'\n",
    "\n",
    "    maple_train_df.loc[maple_train_df['Path'] != pathway_name.replace('_', ' '), 'Class'] = 'negative'\n",
    "    maple_test_df.loc[maple_test_df['Path'] != pathway_name.replace('_', ' '), 'Class'] = 'negative'\n",
    "    maple_eval_df.loc[maple_eval_df['Path'] != pathway_name.replace('_', ' '), 'Class'] = 'negative'\n",
    "\n",
    "    train_df_prep = maple_train_df[attributes]\n",
    "    test_df_prep = maple_test_df[attributes]\n",
    "    eval_df_prep = maple_eval_df[attributes]\n",
    "\n",
    "    train_df_prep.to_csv('Datasets/'+pathway_name+'_train.csv', index=False)\n",
    "    test_df_prep.to_csv('Datasets/'+pathway_name+'_test.csv', index=False)\n",
    "    eval_df_prep.to_csv('Datasets/'+pathway_name+'_eval.csv', index=False)\n",
    "    \n",
    "    if (i == 1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amine_and_polyamine', 'amino_acid']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathway_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "# by: @invoktheshell\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)):\n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, recall_score, precision_score\n",
    "\n",
    "def calc_metrics(y_true, y_pred, model_name, pw_name, dataset_name, fold_num):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    tp, fp, tn, fn = perf_measure(y_true, y_pred)\n",
    "    recall = precision_score(y_true, y_pred)\n",
    "    specifity = tn / (tn + fp)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    # print(precision, specifity, tp,fp,tn,fn)\n",
    "    \n",
    "    try:\n",
    "        fpr = fp / (fp + tn)\n",
    "    except:\n",
    "        fpr = 0\n",
    "        \n",
    "    try:\n",
    "        tpr = tp / (tp + fn)\n",
    "    except:\n",
    "        tpr = 0\n",
    "    \n",
    "    try:\n",
    "        fnr = fn / (fn + tp)\n",
    "    except:\n",
    "        fnr = 0\n",
    "    \n",
    "    try:\n",
    "        fdr = fp / (fp + tp)\n",
    "    except:\n",
    "        fdr = 0\n",
    "    \n",
    "    return model_name, pw_name, dataset_name, fold_num, acc, f1, mcc, tp, fp, tn, fn, recall, precision, specifity, fpr, tpr, fnr, fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10fold_results_amine_and_polyamine.csv  is done.\n",
      "10fold_results_amino_acid.csv  is done.\n"
     ]
    }
   ],
   "source": [
    "#.3 Metabolic pathway modeling and analysis\n",
    "# The 10-fold cross-validation and bagging were used on all training process,\n",
    "# and the metrics accuracy, percentage of correctly classified instances (CCI),\n",
    "# true positive (TP) rate, false positive (FP) rate, false negative (FN) rate, recall,\n",
    "# specificity, F-measure, false discovery rate (FDR), and Matthews coefficient correlation (MCC)\n",
    "# were used to evaluate the predictive performances.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "res_dict = defaultdict(list)\n",
    "# res = []\n",
    "\n",
    "for pathway_name in pathway_names:\n",
    "    train_df = pd.read_csv('Datasets/'+ pathway_name+'_train.csv')\n",
    "    # test_df = pd.read_csv('Datasets/'+ pathway_name+'_test.csv')\n",
    "    # eval_df = pd.read_csv('Datasets/'+ pathway_name+'_eval.csv')\n",
    "    \n",
    "    # print('pathway: ', pathway_name)\n",
    "    # print(len(train_df[train_df[\"Class\"]=='positive']))\n",
    "    \n",
    "    train_df[\"Class\"] = train_df[\"Class\"].apply(lambda x: 1 if x=='positive' else 0)\n",
    "    # test_df[\"Class\"] = test_df[\"Class\"].apply(lambda x: 1 if x=='positive' else 0)\n",
    "    # eval_df[\"Class\"] = eval_df[\"Class\"].apply(lambda x: 1 if x=='positive' else 0)\n",
    "    \n",
    "    names = ['svc', 'nb', 'dt', 'mlp', 'knn', 'rf', 'sgd']\n",
    "    models = [BaggingClassifier(SVC()),\n",
    "              BaggingClassifier(GaussianNB()),\n",
    "              BaggingClassifier(DecisionTreeClassifier()),\n",
    "              BaggingClassifier(MLPClassifier()),\n",
    "              BaggingClassifier(KNeighborsClassifier()),\n",
    "              BaggingClassifier(RandomForestClassifier()),\n",
    "              BaggingClassifier(SGDClassifier()),]\n",
    "    \n",
    "    # 'shuffle' is added, bc 'random_state' is set\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=1337, shuffle=True)\n",
    "    X = train_df.drop('Class', axis=1)\n",
    "    y = train_df[\"Class\"]\n",
    "    \n",
    "    res = []\n",
    "    for i in range(len(models)):\n",
    "        fold_num=0\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            fold_num+=1\n",
    "            X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "            y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "            models[i].fit(X_train, y_train)\n",
    "            preds = models[i].predict(X_test)\n",
    "            # print(y_test[y_test[]])\n",
    "            # res.append(calc_metrics(y_test.tolist(), preds.tolist(), names[i], pathway_name, 'test_df', fold_num))\n",
    "            res.append(calc_metrics(y_test.tolist(), preds.tolist(), names[i], pathway_name, 'test_df', fold_num))\n",
    "\n",
    "    res_df = pd.DataFrame(res, columns=[\"model_name\", \"pw_name\", \"dataset_name\", \"fold_num\", \"acc\", \"f1\", \"mcc\", \"tp\", \"fp\", \"tn\", \"fn\", \"recall\", \"precision\", \"specifity\", \"fpr\", \"tpr\", \"fnr\", \"fdr\"])\n",
    "    res_dict[pathway_name] = res_df\n",
    "    \n",
    "    file_name = '10fold_results_' + pathway_name + '.csv'\n",
    "    \n",
    "    res_df.to_csv(file_name, index=False)\n",
    "    print(file_name, \"is done.\")\n",
    "    \n",
    "del y_test, y_train, X_test, X_train, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>specifity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>fdr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.992531</td>\n",
       "      <td>0.881797</td>\n",
       "      <td>0.881604</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>529.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.947808</td>\n",
       "      <td>0.947808</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.829532</td>\n",
       "      <td>0.170468</td>\n",
       "      <td>0.052192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.995810</td>\n",
       "      <td>0.933513</td>\n",
       "      <td>0.934135</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>530.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877485</td>\n",
       "      <td>0.122515</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.993624</td>\n",
       "      <td>0.901186</td>\n",
       "      <td>0.899846</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>529.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.942729</td>\n",
       "      <td>0.942729</td>\n",
       "      <td>0.998114</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.866959</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>0.057271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.845504</td>\n",
       "      <td>0.292756</td>\n",
       "      <td>0.359638</td>\n",
       "      <td>17.2</td>\n",
       "      <td>83.2</td>\n",
       "      <td>446.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.175160</td>\n",
       "      <td>0.175160</td>\n",
       "      <td>0.843050</td>\n",
       "      <td>0.156950</td>\n",
       "      <td>0.914327</td>\n",
       "      <td>0.085673</td>\n",
       "      <td>0.824840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.993076</td>\n",
       "      <td>0.884055</td>\n",
       "      <td>0.888080</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>530.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.796784</td>\n",
       "      <td>0.203216</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.994717</td>\n",
       "      <td>0.916128</td>\n",
       "      <td>0.916771</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>529.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.983224</td>\n",
       "      <td>0.983224</td>\n",
       "      <td>0.999434</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.861696</td>\n",
       "      <td>0.138304</td>\n",
       "      <td>0.016776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.995263</td>\n",
       "      <td>0.923086</td>\n",
       "      <td>0.924770</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>530.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.861696</td>\n",
       "      <td>0.138304</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 acc        f1       mcc    tp    fp     tn   fn    recall  \\\n",
       "model_name                                                                   \n",
       "dt          0.992531  0.881797  0.881604  15.6   0.9  529.2  3.2  0.947808   \n",
       "knn         0.995810  0.933513  0.934135  16.5   0.0  530.1  2.3  1.000000   \n",
       "mlp         0.993624  0.901186  0.899846  16.3   1.0  529.1  2.5  0.942729   \n",
       "nb          0.845504  0.292756  0.359638  17.2  83.2  446.9  1.6  0.175160   \n",
       "rf          0.993076  0.884055  0.888080  15.0   0.0  530.1  3.8  1.000000   \n",
       "sgd         0.994717  0.916128  0.916771  16.2   0.3  529.8  2.6  0.983224   \n",
       "svc         0.995263  0.923086  0.924770  16.2   0.0  530.1  2.6  1.000000   \n",
       "\n",
       "            precision  specifity       fpr       tpr       fnr       fdr  \n",
       "model_name                                                                \n",
       "dt           0.947808   0.998302  0.001698  0.829532  0.170468  0.052192  \n",
       "knn          1.000000   1.000000  0.000000  0.877485  0.122515  0.000000  \n",
       "mlp          0.942729   0.998114  0.001886  0.866959  0.133041  0.057271  \n",
       "nb           0.175160   0.843050  0.156950  0.914327  0.085673  0.824840  \n",
       "rf           1.000000   1.000000  0.000000  0.796784  0.203216  0.000000  \n",
       "sgd          0.983224   0.999434  0.000566  0.861696  0.138304  0.016776  \n",
       "svc          1.000000   1.000000  0.000000  0.861696  0.138304  0.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('10fold_results_amine_and_polyamine.csv').drop('fold_num', axis=1).groupby('model_name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>specifity</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>fdr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.963200</td>\n",
       "      <td>0.722646</td>\n",
       "      <td>0.727574</td>\n",
       "      <td>26.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>502.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.943446</td>\n",
       "      <td>0.943446</td>\n",
       "      <td>0.996825</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.587391</td>\n",
       "      <td>0.412609</td>\n",
       "      <td>0.056554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.973038</td>\n",
       "      <td>0.810392</td>\n",
       "      <td>0.806698</td>\n",
       "      <td>32.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>501.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.942145</td>\n",
       "      <td>0.942145</td>\n",
       "      <td>0.996030</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.715894</td>\n",
       "      <td>0.284106</td>\n",
       "      <td>0.057855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.972309</td>\n",
       "      <td>0.804793</td>\n",
       "      <td>0.800821</td>\n",
       "      <td>32.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>501.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.935837</td>\n",
       "      <td>0.935837</td>\n",
       "      <td>0.995634</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.711401</td>\n",
       "      <td>0.288599</td>\n",
       "      <td>0.064163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.460742</td>\n",
       "      <td>0.212557</td>\n",
       "      <td>0.171722</td>\n",
       "      <td>39.8</td>\n",
       "      <td>290.7</td>\n",
       "      <td>213.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.120911</td>\n",
       "      <td>0.120911</td>\n",
       "      <td>0.422993</td>\n",
       "      <td>0.577007</td>\n",
       "      <td>0.882271</td>\n",
       "      <td>0.117729</td>\n",
       "      <td>0.879089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.962653</td>\n",
       "      <td>0.703954</td>\n",
       "      <td>0.722946</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545314</td>\n",
       "      <td>0.454686</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.959556</td>\n",
       "      <td>0.692035</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>25.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>501.3</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.909598</td>\n",
       "      <td>0.909598</td>\n",
       "      <td>0.995038</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.562995</td>\n",
       "      <td>0.437005</td>\n",
       "      <td>0.090402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.964840</td>\n",
       "      <td>0.726296</td>\n",
       "      <td>0.741009</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>503.7</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.996296</td>\n",
       "      <td>0.996296</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.574058</td>\n",
       "      <td>0.425942</td>\n",
       "      <td>0.003704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 acc        f1       mcc    tp     fp     tn    fn    recall  \\\n",
       "model_name                                                                     \n",
       "dt          0.963200  0.722646  0.727574  26.5    1.6  502.2  18.6  0.943446   \n",
       "knn         0.973038  0.810392  0.806698  32.3    2.0  501.8  12.8  0.942145   \n",
       "mlp         0.972309  0.804793  0.800821  32.1    2.2  501.6  13.0  0.935837   \n",
       "nb          0.460742  0.212557  0.171722  39.8  290.7  213.1   5.3  0.120911   \n",
       "rf          0.962653  0.703954  0.722946  24.6    0.0  503.8  20.5  1.000000   \n",
       "sgd         0.959556  0.692035  0.695799  25.4    2.5  501.3  19.7  0.909598   \n",
       "svc         0.964840  0.726296  0.741009  25.9    0.1  503.7  19.2  0.996296   \n",
       "\n",
       "            precision  specifity       fpr       tpr       fnr       fdr  \n",
       "model_name                                                                \n",
       "dt           0.943446   0.996825  0.003175  0.587391  0.412609  0.056554  \n",
       "knn          0.942145   0.996030  0.003970  0.715894  0.284106  0.057855  \n",
       "mlp          0.935837   0.995634  0.004366  0.711401  0.288599  0.064163  \n",
       "nb           0.120911   0.422993  0.577007  0.882271  0.117729  0.879089  \n",
       "rf           1.000000   1.000000  0.000000  0.545314  0.454686  0.000000  \n",
       "sgd          0.909598   0.995038  0.004962  0.562995  0.437005  0.090402  \n",
       "svc          0.996296   0.999802  0.000198  0.574058  0.425942  0.003704  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('10fold_results_amino_acid.csv').drop('fold_num', axis=1).groupby('model_name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df.drop('fold_num', axis=1).loc[res_df[\"pw_name\"] == \"amine_and_polyamine\"].groupby('model_name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amine_and_polyamine dt knn\n",
      "Statistics=0.019, p=0.890\n",
      "\n",
      "amine_and_polyamine dt mlp\n",
      "Statistics=0.076, p=0.783\n",
      "\n",
      "amine_and_polyamine dt nb\n",
      "Statistics=0.414, p=0.520\n",
      "\n",
      "amine_and_polyamine dt rf\n",
      "Statistics=0.002, p=0.963\n",
      "\n",
      "amine_and_polyamine dt sgd\n",
      "Statistics=0.019, p=0.890\n",
      "\n",
      "amine_and_polyamine dt svc\n",
      "Statistics=0.019, p=0.890\n",
      "\n",
      "amine_and_polyamine knn mlp\n",
      "Statistics=0.005, p=0.945\n",
      "\n",
      "amine_and_polyamine knn nb\n",
      "Statistics=0.135, p=0.713\n",
      "\n",
      "amine_and_polyamine knn rf\n",
      "Statistics=0.013, p=0.908\n",
      "\n",
      "amine_and_polyamine knn sgd\n",
      "Statistics=0.034, p=0.854\n",
      "\n",
      "amine_and_polyamine knn svc\n",
      "Statistics=0.013, p=0.908\n",
      "\n",
      "amine_and_polyamine mlp nb\n",
      "Statistics=0.541, p=0.462\n",
      "\n",
      "amine_and_polyamine mlp rf\n",
      "Statistics=0.090, p=0.765\n",
      "\n",
      "amine_and_polyamine mlp sgd\n",
      "Statistics=0.019, p=0.890\n",
      "\n",
      "amine_and_polyamine mlp svc\n",
      "Statistics=0.005, p=0.945\n",
      "\n",
      "amine_and_polyamine nb rf\n",
      "Statistics=0.076, p=0.783\n",
      "\n",
      "amine_and_polyamine nb sgd\n",
      "Statistics=0.357, p=0.550\n",
      "\n",
      "amine_and_polyamine nb svc\n",
      "Statistics=0.135, p=0.713\n",
      "\n",
      "amine_and_polyamine rf sgd\n",
      "Statistics=0.002, p=0.963\n",
      "\n",
      "amine_and_polyamine rf svc\n",
      "Statistics=0.013, p=0.908\n",
      "\n",
      "amine_and_polyamine sgd svc\n",
      "Statistics=0.043, p=0.836\n",
      "\n",
      "amino_acid dt knn\n",
      "Statistics=0.002, p=0.963\n",
      "\n",
      "amino_acid dt mlp\n",
      "Statistics=0.002, p=0.963\n",
      "\n",
      "amino_acid dt nb\n",
      "Statistics=0.610, p=0.435\n",
      "\n",
      "amino_acid dt rf\n",
      "Statistics=0.104, p=0.747\n",
      "\n",
      "amino_acid dt sgd\n",
      "Statistics=0.034, p=0.854\n",
      "\n",
      "amino_acid dt svc\n",
      "Statistics=0.019, p=0.890\n",
      "\n",
      "amino_acid knn mlp\n",
      "Statistics=0.034, p=0.854\n",
      "\n",
      "amino_acid knn nb\n",
      "Statistics=0.610, p=0.435\n",
      "\n",
      "amino_acid knn rf\n",
      "Statistics=0.171, p=0.679\n",
      "\n",
      "amino_acid knn sgd\n",
      "Statistics=0.076, p=0.783\n",
      "\n",
      "amino_acid knn svc\n",
      "Statistics=0.076, p=0.783\n",
      "\n",
      "amino_acid mlp nb\n",
      "Statistics=0.610, p=0.435\n",
      "\n",
      "amino_acid mlp rf\n",
      "Statistics=0.171, p=0.679\n",
      "\n",
      "amino_acid mlp sgd\n",
      "Statistics=0.076, p=0.783\n",
      "\n",
      "amino_acid mlp svc\n",
      "Statistics=0.076, p=0.783\n",
      "\n",
      "amino_acid nb rf\n",
      "Statistics=0.104, p=0.747\n",
      "\n",
      "amino_acid nb sgd\n",
      "Statistics=0.610, p=0.435\n",
      "\n",
      "amino_acid nb svc\n",
      "Statistics=0.104, p=0.748\n",
      "\n",
      "amino_acid rf sgd\n",
      "Statistics=0.019, p=0.890\n",
      "\n",
      "amino_acid rf svc\n",
      "Statistics=0.008, p=0.927\n",
      "\n",
      "amino_acid sgd svc\n",
      "Statistics=0.002, p=0.963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The best classifiers for each metabolic pathway were ranked using the Kruskal-Wallis test.\n",
    "# Bu test algoritmaları nasıl sıralıyor anlamadım, benim anladığım fark var mı diye bakıyor dağılımlarda\n",
    "\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# res_rows = res_df.drop('fold_num', axis=1).groupby('model_name').mean()\n",
    "for pw_name, df in res_dict.items():\n",
    "    res_rows = df.drop('fold_num', axis=1).groupby('model_name').mean()\n",
    "\n",
    "    for i in range(len(res_rows.index)):\n",
    "        for j in range(i+1, len(res_rows.index)):\n",
    "            print(pw_name, \"-\", str(res_rows.index[i]), \"-\", str(res_rows.index[j]))\n",
    "            stat, p = kruskal(res_rows.loc[str(res_rows.index[i])], res_rows.loc[str(res_rows.index[j])])\n",
    "            print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "            if kr.pvalue < 0.05:\n",
    "                print(\"statistically significant p value is found: \", str(res_rows.index[i], str(res_rows.index[j])))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc            0.845504\n",
       "f1             0.292756\n",
       "mcc            0.359638\n",
       "tp            17.200000\n",
       "fp            83.200000\n",
       "tn           446.900000\n",
       "fn             1.600000\n",
       "recall         0.175160\n",
       "precision      0.175160\n",
       "specifity      0.843050\n",
       "fpr            0.156950\n",
       "tpr            0.914327\n",
       "fnr            0.085673\n",
       "fdr            0.824840\n",
       "Name: nb, dtype: float64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict[\"amine_and_polyamine\"].drop('fold_num', axis=1).groupby('model_name').mean().loc[\"nb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best classifiers were pre-selected, seeking a low FP & high F-measure and CCI\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "best_models = {}    # {\"pathway\": [best 3 models]}\n",
    "\n",
    "for pw_name, df in res_dict.items():\n",
    "    df = df.drop('fold_num', axis=1).groupby('model_name').mean()\n",
    "    \n",
    "    models = []\n",
    "    scores = {}\n",
    "    for i in range(len(df)):\n",
    "        model = str(res_rows.index[i])\n",
    "        row = df.loc[model]\n",
    "\n",
    "        # low FP\n",
    "        FP = row[\"fp\"]\n",
    "        \n",
    "        # high f-measure\n",
    "        F1 = row[\"f1\"]\n",
    "        \n",
    "        # high percentage of correctly classified instances\n",
    "        CCI = row[\"acc\"]\n",
    "\n",
    "        score = (CCI + F1) - FP\n",
    "        scores[model] = score\n",
    "        \n",
    "    scores = OrderedDict(sorted(scores.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    \n",
    "    i = 0\n",
    "    for model, score in scores.items():\n",
    "        if (i == 3):\n",
    "            break\n",
    "        \n",
    "        models.append(model)\n",
    "        i += 1\n",
    "    \n",
    "    best_models[pw_name] = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('rf', 1.66660625964676),\n",
       "             ('svc', 1.5911357528288048),\n",
       "             ('dt', 0.08584549131292851),\n",
       "             ('knn', -0.21657021269860977),\n",
       "             ('mlp', -0.4228980122630448),\n",
       "             ('sgd', -0.8484098342774564),\n",
       "             ('nb', -290.0267013095288)])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amine_and_polyamine': ['knn', 'svc', 'rf'],\n",
       " 'amino_acid': ['rf', 'svc', 'dt']}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators for bagging classifier\n",
    "bagging_cls = {'svc': ('svc', BaggingClassifier(SVC())),\n",
    "               'dt': ('dt', BaggingClassifier(DecisionTreeClassifier())),\n",
    "               'mlp': ('mlp', BaggingClassifier(MLPClassifier())),\n",
    "               'nb' : ('nb', BaggingClassifier(GaussianNB())),\n",
    "               'rf': ('rf', BaggingClassifier(RandomForestClassifier())),\n",
    "               'knn': ('knn', BaggingClassifier(KNeighborsClassifier())),\n",
    "               'sgd': ('sgd', BaggingClassifier(SGDClassifier()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {'rf__base_estimator__bootstrap': [True],\n",
    "             'rf__base_estimator__max_depth': [80, 100]}\n",
    "# 'rf__base_estimator__max_features': [2, 3]\n",
    "# 'rf__base_estimator__min_samples_leaf': [3, 4],\n",
    "# 'rf__base_estimator__min_samples_split': [8, 10],\n",
    "# 'rf__base_estimator__n_estimators': [100, 200] \n",
    "\n",
    "params_SVC={'svc__base_estimator__C': [1, 100, 1000],\n",
    "            'svc__base_estimator__gamma': [1, 0.01, 0.0001] }\n",
    "# 'svc__base_estimator__kernel': ['rbf']\n",
    "\n",
    "params_MLP = {'mlp__base_estimator__hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "              'mlp__base_estimator__activation': ['tanh', 'relu'] }\n",
    "# 'mlp__base_estimator__solver': ['sgd', 'adam'],\n",
    "# 'mlp__base_estimator__alpha': [0.0001, 0.05],\n",
    "# 'mlp__base_estimator__learning_rate': ['constant','adaptive']\n",
    "\n",
    "params_DT = { 'dt__base_estimator__max_depth': list(range(1,10)),\n",
    "              'dt__base_estimator__min_samples_leaf': list(range(1,10,2))}\n",
    "\n",
    "params_KNN = { 'knn__base_estimator__n_neighbors': list(range(1, 31)) }\n",
    "\n",
    "params_SGD = {\n",
    "    'sgd__base_estimator__penalty': ['l2'],\n",
    "    'sgd__base_estimator__n_jobs': [-1] }\n",
    "# 'sgd__base_estimator__C': [1e-7, 1e-5, 1e-3]\n",
    "\n",
    "all_params = {\"rf\": params_rf, \n",
    "              \"svc\": params_SVC, \n",
    "              \"mlp\": params_MLP, \n",
    "              \"dt\": params_DT, \n",
    "              \"knn\": params_KNN, \n",
    "              \"sgd\": params_SGD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_models_w_params = {}    # [\"pathway\": (voting model, parameters)]\n",
    "\n",
    "for pw_name, models in best_models.items():\n",
    "    \n",
    "    estimators = []\n",
    "    parameters = {}\n",
    "    \n",
    "    for model in models:\n",
    "        # model's estimator\n",
    "        estimators.append(bagging_cls[model])\n",
    "        \n",
    "        # there is no param for NB\n",
    "        if model in all_params.keys():\n",
    "            for param, values in all_params[model].items():\n",
    "                parameters[param] = values\n",
    "                \n",
    "    # pramameters = \n",
    "        \n",
    "    voting_model = VotingClassifier(estimators=estimators, voting='soft')\n",
    "    voting_models_w_params[pw_name] = (voting_model, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting for amine_and_polyamine\n",
      "Fitting 2 folds for each of 180 candidates, totalling 360 fits\n",
      "0.9368153506734713\n",
      "{'dt__base_estimator__max_depth': 5, 'dt__base_estimator__min_samples_leaf': 9, 'mlp__base_estimator__activation': 'relu', 'mlp__base_estimator__hidden_layer_sizes': (20,)}\n",
      "Starting for amino_acid\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6855790501839225\n",
      "{'mlp__base_estimator__activation': 'tanh', 'mlp__base_estimator__hidden_layer_sizes': (20,), 'sgd__base_estimator__n_jobs': -1, 'sgd__base_estimator__penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# parameters tuning of combined algorithms\n",
    "\n",
    "best_scores = {}    # \"model\": best scores\n",
    "best_params = {}    # \"model\": best parameters\n",
    "\n",
    "for pathway_name in pathway_names:\n",
    "    df = pd.read_csv('Datasets/' + pathway_name+'_train.csv')\n",
    "    \n",
    "    voting_model = voting_models_w_params[pathway_name][0]\n",
    "    parameters = voting_models_w_params[pathway_name][1]\n",
    "    \n",
    "    print(\"Starting for\", pathway_name)\n",
    "    clf = GridSearchCV(voting_model, parameters, n_jobs=-1, verbose=3, scoring='f1_macro', cv=2)\n",
    "    clf.fit(df.drop('Class', axis=1), df[\"Class\"])\n",
    "    \n",
    "    best_scores[pathway_name] = clf.best_score_\n",
    "    best_params[pathway_name] = clf.best_params_\n",
    "\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amine_and_polyamine': 0.9368153506734713, 'amino_acid': 0.6855790501839225}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amine_and_polyamine': {'dt__base_estimator__max_depth': 5,\n",
       "  'dt__base_estimator__min_samples_leaf': 9,\n",
       "  'mlp__base_estimator__activation': 'relu',\n",
       "  'mlp__base_estimator__hidden_layer_sizes': (20,)},\n",
       " 'amino_acid': {'mlp__base_estimator__activation': 'tanh',\n",
       "  'mlp__base_estimator__hidden_layer_sizes': (20,),\n",
       "  'sgd__base_estimator__n_jobs': -1,\n",
       "  'sgd__base_estimator__penalty': 'l2'}}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
